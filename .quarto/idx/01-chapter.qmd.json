{"title":"Overview","markdown":{"yaml":{"title":"Overview","author":"Alex Trinidad (Chair)","format":{"html":{"grid":{"margin-width":"350px"}},"pdf":"default"},"reference-location":"margin","citation-location":"margin"},"headingText":"Summary","containsRefs":false,"markdown":"\n\n\nThis firstnchapter lays out the key challenges of statistical inference in general and regression modeling in particular.\n\n::: column-margin\nInference defined as using mathematical models to make general claims from particular data\n:::\n\nThere are three challenges to statistics, which all can be framed as problems of prediction:\\\n- Generalizing from sample to population;\\\n- Generalizing from treatment to control group;\\\n- Generalizing from observed measurements to the underlying construct of interest.\n\nThe key skills you learn in this book are: \\\n- Understanding regression models;\\\n- Constructing regression models;\\\n- Fitting regression models to data;\\\n- Displaying and interpreting the results of regression models;\n\nRegression is a method that allows researchers to summarize how predictions or average values of an *outcome* vary across individuals defined by a set of *predictors*. It is used for example to predict, to explore associations, to extrapolate and for causal inference. Exmaples are given.\n\nThere are four steps in statistical analysis: \\\n- Model building (starting);\\\n- Model fitting;\\\n- Understanding model fits;\\\n- Criticism.\n\nFitting models and making predictions can be down different frameworks. Three concerns are important everytime: \n- Information used;\\\n- Assumptions used;\\\n- Estimating and interpreting (classical or Bayesian framework).\n\nGelman et all. recommend to use the Bayesian framework. If information available you can use it, if not you can use weakly informative default priors. On this way you stable estimates and with the simulations you can express uncertainty.\n\nThe overall Bayesian regression in R is:\n\n:::{.panel-tabset}\n\n## rstanarm\n\n\n```         \nfit<-stan_glm(y~x,data=mydata)\n```\n\n::: column-margin\nBayes can take longer time. Here you can use\n\n```         \nfit<-stan_glm(y~x,data=mydata,algorithm=\"optimizing\")\n```\n:::\n\n## brms\n```\nfit<-brm(y~x,data=mydata)\n```\n\n:::\n\n\n\nWhere y is the outcome, x is the predictor and mydata is the data frame. But you can do it also in classical framework:\n\n```         \nfit<-lm(y~x,data=mydata)\n```\n\nUsing Bayesian and simulation approaches can be more important when fitting multilevel or regularized regression models. This will be handled in their next book.\n\n## Presentation\n\nFirst some libraries are loaded.\n\n```{r warning=FALSE, message=FALSE}\nlibrary(rosdata) # for the ROSdata\nlibrary(dplyr)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(rstanarm) # for the stan_glm function\nlibrary(brms) # for the brm function\n```\n\n\n\n## Presentation\nOn 14-11-2023 Alex Trinidad (University of Cologne and Netherlands Institute for the Study of Crime and Law Enforcement) presented the first chapter of the book *Regression and Other Stories* by Andrew Gelman, Jennifer Hill, and Aki Vehtari: **Overview**. The session was held online via Zoom.\n[Here]() you can find Alex' script Trinidad.\n\nFirst he loaded this package.\n\n```{r message=FALSE, warning=FALSE}\n#| label: load-packages\n\nlibrary(tidyverse)\n```\n\n\n\n1. Regression to predict \n\nHow can we predict presidential vote share using economy growth? For this he loaded the ROS-data.\n\n```{r}\n#| label: load-data1\n\nelections_data <- read.csv(url(\"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/ElectionsEconomy/data/hibbs.dat\"), sep = \"\")\n\n```\n\nThis another way to load these data.\n\n```{r}\n#| label: load-data2\n\nremotes::install_github(\"avehtari/ROS-Examples\", subdir = \"rpackage\")\nelections_data <- rosdata::hibbs\n```\n\n\nLet us first explore economy growth.\n\n```{r}\n#| label: explore-data\n\nglimpse(elections_data)\n```\nTry the view-function yourself.\n\n```{r}\n# View(elections_data)\n```\n\nUse visualization to understand the data.\n\n```{r}\n#| label: plot-data1\n#| fig.cap: \"Predicting elections from the economy 1952-2016\"\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = year, y = growth))\n\n```\n\nAdd a line to the plot.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-data2\n#| fig.cap: \"Predicting elections from the economy 1952-2016 with line\"\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = year, y = growth)) +\n  geom_smooth(aes(x = year, y = growth), se = FALSE)\n```\n\nAdd the CI around the line.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-data3\n#| fig.cap: \"Predicting elections from the economy 1952-2016 with line and confidence interval\"\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = year, y = growth)) +\n  geom_smooth(aes(x = year, y = growth), se = TRUE)\n```\n\nFit ols-regression to obtain the predicted values.\n\n```{r}\n#| label: fit-ols\n\nmod1 <- lm(vote ~ growth, data = elections_data)\n```\n\nSummarize the regression results.\n\n```{r}\n#| label: summary-ols\n\nsummary(mod1)\n```\n\nPlot the predicted values.\n\n```{r}\n#| label: plot-predicted\n#| column: margin\n#| fig.cap: \"Predicting elections from the economy 1952-2016 with line\"\n\nplot(elections_data$growth, elections_data$vote, xlab = \"Economic Growth\", ylab = \"Vote Share\")\nabline(coef(mod1), col = \"red\")\n```\nPredicted values with ggplot.\n\n```{r}\n#| label: plot-predicted2\n#| column: margin\n  \nggplot(data = elections_data) +\n  geom_point(aes(x = growth, y = vote)) +\n  geom_abline(intercept = mod1[[1]][[1]], slope = mod1[[1]][[2]], color = \"red\", size = 1) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  scale_y_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  geom_hline(yintercept = 50) +\n  labs(title = \"Data and linear fit\",\n       x = \"Average recent growth in personal income\",\n       y = \"Incumbent party's vote share\")\n```\n\nPredicted values with ggplot and geom_smooth.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-predicted3\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = growth, y = vote)) +\n  geom_smooth(method = \"lm\", aes(x = growth, y = vote), color = \"blue\", size = 1) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  scale_y_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  geom_hline(yintercept = 50) +\n  labs(title = \"Data and linear fit\",\n       x = \"Average recent growth in personal income\",\n       y = \"Incumbent party's vote share\")\n```\n\n2. Sketching regression \n\nOriginal $y = 46.3 + 3.0 x$. Explore the descriptive stats to get some parameters based on the observed data.\n\n```{r}\n#| label: descriptive-stats\n\nelections_data |> \n  summarise(min_growth = min(growth),\n            max_growth = max(growth),\n            mean_growth = mean(growth),\n            sd_growth = sd(growth),\n            min_vote = min(vote),\n            max_vote = max(vote),\n            mean_vote = mean(vote),\n            sd_vote = sd(vote))\n```\n\nSimulating the data (technique often used in this book).\n\n```{r}\n#| label: simulate-data\nset.seed(123)\nN <- 16\nsimu_growth <- runif(N, -0.39, 4)\nsimu_vote <- rnorm(N, 46.2476  + 3.0605*simu_growth, 3.763)\nsimu_elections <- data.frame(N,simu_growth, simu_vote)\n```\n\nModel the simulated data.\n\n```{r}\n#| label: model-simulated\nsimu_mod <- lm(simu_vote ~ simu_growth, data = simu_elections)\n```\n\nSummarize the model.\n\n```{r}\n#| label: summary-simulated\nsummary(simu_mod)\n```\n\nPlot the simulated data using base graphics.\n\n```{r}\n#| label: plot-simulated\n#| column: margin\n#| fig.cap: \"Simulated Data and linear fit\"\n\n# Base graphic\nplot(simu_elections$simu_growth, simu_elections$simu_vote, xlab = \"Simulated Economic Growth\", ylab = \"Simulated Vote Share\")\nabline(coef(simu_mod), col = \"blue\")\n```\n\nPlot the samen using ggplot version.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-simulated2\n#| column: margin\n \nggplot(data = simu_elections) +\n  geom_point(aes(x = simu_growth, y = simu_vote)) +\n  geom_smooth(method = \"lm\", aes(x = simu_growth, y = simu_vote), color = \"blue\", size = 1) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  scale_y_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  geom_hline(yintercept = 50) +\n  labs(title = \"Simulated Data and linear fit\",\n       x = \"Simulated Average recent growth in personal income\",\n       y = \"Simulated Incumbent party's vote share\")\n```\n\nExercise 1.2(a) from ROS for sketching a regression model and data. \n\na) $y = 30 + 10x$  (residual $sd 3.9$) & values of X ranging from $0-4$ \n\nDefine the data.\n\n```{r}\n#| label: exercise-1.2\n\nset.seed(123)\nN <- 50\nx <- runif(N, 0, 4)\ny <- rnorm(N, 30 + 10*x, 3.9)\ndata <- data.frame(N, x, y)\n```\n\nModel the data.\n\n```{r}\n#| label: exercise-1.2-model\nlm_a <- lm(y ~ x, data)\n```\n\nPlot the data.\n\n```{r}\n#| label: exercise-1.2-plot\n#| column: margin\n#| fig.cap: \"Exercise 1.2 from ROS\"\n\nplot(data$x, data$y, xlab = \"X Value\", ylab = \"Y value\")\nabline(coef(lm_a), col = \"red\", size = 1)\n```\n\nb) $y = 30 + 10x$  (residual $sd 10$) & values of X ranging from $0-4$. \n\nDefine the data.\n\n```{r}\n#| label: exercise-1.2b\n\nset.seed(123)\nN <- 50\nx <- runif(N, 0, 4)\ny <- rnorm(N, 30 + 10*x, 10)\ndata <- data.frame(N, x, y)\n```\n\nModel it.\n\n```{r}\n#| label: exercise-1.2b-model\n\nlm_b <- lm(y ~ x, data)\n```\n\nPlot it.\n\n```{r}\n#| label: exercise-1.2b-plot\n#| column: margin\n#| fig.cap: \"Continuous predictor\"\n\nplot(data$x, data$y, xlab = \"X Value\", ylab = \"Y value\")\nabline(coef(lm_b), col = \"blue\")\n```\n\nNow simulate a binary predictor [example from the Aki Vehtari GH](https://avehtari.github.io/ROS-Examples/SimpleCausal/causal.html)\n\nSee Figure 1.5 (page 10).\n\n```{r}\n#| label: binary-predictor\n\nset.seed(1411)\nN <- 50\nx <- runif(N, 0, 4)\ny <- rnorm(N, 30 + 10*x, 10)\nx_binary <- ifelse(x < 3, 0, 1)\ndata_simu <- data.frame(N, x, y, x_binary)\n```\n\nModel it.\n\n```{r}\n#| label: binary-predictor-model\n\nlm_binary <- lm(y ~ x_binary, data = data_simu)\n```\n\nSummarize the model.\n\n```{r}\n#| label: binary-predictor-summary\nsummary(lm_binary)\n```\n\nPlot the relationship.\n\n```{r}\n#| label: binary-predictor-plot\n#| column: margin\n#| fig.cap: \"Binary predictor\"\n\nggplot(data = data_simu) +\n  geom_point(aes(x = x_binary, y = y)) +\n  geom_abline(intercept = lm_binary[[1]][[1]], slope = lm_binary[[1]][[2]],\n              color = \"blue\", size = 1) +\n  labs(y = \"Crime reduction\", \n       x =  NULL) +\n  scale_x_continuous(breaks = c(0,1),\n                     labels = c(\"Control\", \"Treatment\")) +\n  annotate(geom = \"text\", x = 0.50, y = 40,\n           label = paste(\"Estimated treatment effect is\\nslope of fitted line: \",\n                         round(lm_binary[[1]][[2]], digits = 2)))\n```\n\nNon-linear relationship \n\n```{r}\n#| label: non-linear\n\nset.seed(1411)\nx <- runif(N, 1, 7)\ny <- rnorm(N, 7 + 30*exp(-x), 2)\ndata_simu$y <- y\n```\n\nFit the model. \n\n```{r}\n#| label: non-linear-model\n\nlm_nonlinear <- lm(y ~ x, data = data_simu)\n```\n\nSummarize the model.\n\n```{r}\n#| label: non-linear-summary\n\nsummary(lm_nonlinear)\n```           \n\nPlot the model outcome.\n\n```{r message=FALSE, warning=FALSE}\n#| label: non-linear-plot\n#| column: margin\n#| fig.cap: \"Non-linear relationship\"\n\nggplot(data = data_simu) +\n  geom_point(aes(x = x, y = y)) +\n  geom_smooth(method = \"loess\", aes(x = x, y = y), color = \"blue\", size = 1, se = FALSE) +\n  labs(y = \"Theft counts per hour\", \n       x =  \"Hours of foot patrol\")  \n```\n\n## More examples\nFirst look at dataset to predict US-elections (1952-2021) from the economy and explore data.\n\n```{r}\ndata(\"hibbs\")\nglimpse(hibbs)\n```\n\nReplicate the plot of Figure 1.1.\n\n```{r}\n#| label: fig:hibbs\n#| fig-cap: \"Predicting elections from the economy 1952-2016\"\n#| column: margin\n\nggplot(data = hibbs,\n       mapping = aes(x = growth, y = vote)) +\n  # geom_label(mapping = aes(label = year), nudge_x = 0.3, fill = NA, size = 3) +\n  geom_point() \n\n```\n\nNow run the first regression model using `stanarm` or `brms`. This simulation works with four chains and 2000 iterations per chain. \n\n:::{.panel-tabset}\n\n## rstanarm\n\n```{r}\nM1 <- stan_glm(vote ~ growth, data=hibbs)\n```\n\nM1 is set on your computer and you can give a summary of this regression model.\n\n```{r}\nM1\n```\n\nOr print the intercept (46.26) and the slope (3.05) of this model.\n\n```{r}\ncoef(M1)\n```\n\n\n## brms\n\n```{r}\nM2 <- brm(vote ~ growth, data=hibbs)\n```\n\nM2 is set on your computer and you can give a summary of this regression model.\n\n```{r}\nM2 <-\n  brm(data = hibbs,\n      vote ~ growth,\n      cores = 4, chains = 4, iter = 2000,\n      seed = 123)\n\n\n```\n\n```{r}\nM2\n```\n\n\n\n:::\n\nNow add line to plot.\n\n```{r}\n#| label: fig:hibbs2\n#| fig-cap: \"Predicting elections from the economy 1952-2016\"\n#| column: margin\n#| \nggplot(data = hibbs,\n       mapping = aes(x = growth, y = vote)) +\n  geom_point() +\n  geom_abline(slope     = coef(M1)[[\"growth\"]],\n              intercept = coef(M1)[[\"(Intercept)\"]]) \n```\n\n\nWe also looked at the peacekeeping data (1.3). First open the data.\n\n\n```{r warning=FALSE, message=FALSE}\npeace_df <- read_csv(\"~/Desktop/WERK/Gelman/reading_club_GIT/Reading_club_Git/ROS-Examples-master/Peacekeeping/data/minidata.csv\")\n```\n\nExplore this dataset now.\n\n```{r}\nglimpse(peace_df)\n```\n\nCreate date measure. It's actually the same as delay.\n\n```{r}\npeace_df <- peace_df |>\n  mutate(time_diff = (faildate-cfdate)/365)\n```\n\nLet us plot it ...\n\n```{r}\n#| label: fig:peace\n#| fig-cap: \"Outcomes after civil war in countries with and without UN-peacekeepers\"\n#| column: margin\n\n# Harrie: not working\n# peace_df |>\n#  ggplot(data = .) +\n#  geom_histogram(mapping = aes(x = delay), bins = 10) +\n#  facet_wrap(~`peacekeepers?`) \n```\n\n... or put it in a scatterplot.\n\n```{r}\n#| label: fig:peace2\n#| fig-cap: \"Outcomes after civil war in countries with and without UN-peacekeepers\"\n#| column: margin\n\nggplot(data = peace_df) +\n  geom_point(mapping = aes(y = delay,\n                           colour = as.factor(`censored?`),\n                           x = badness,\n                           )) +\n  facet_wrap(~`peacekeepers?`) \n```\n\nMeans.\n\n```{r warning=FALSE, message=FALSE}\npeace_df |> \n  group_by(`peacekeepers?`, `censored?`) |> \n  summarise(mean_badness = mean(badness, na.rm = TRUE))\n```\n\nSimple causal graph for reproducibility of simulated data.\n\n```{r}\nSEED <- 1151\nset.seed(SEED)\nN <- 50\nx <- runif(N, 1, 5)\ny <- rnorm(N, 10 + 3*x, 3)\nx_binary <- ifelse(x<3, 0, 1)\ncausal_df <- data.frame(N, x, y, x_binary)\n```\n\nPlot this.\n\n```{r}\n#| label: fig:causal\n#| fig-cap: \"Causal graph of simulated data\"\n#| column: margin\n#| \nggplot(data = causal_df) +\n  geom_point(mapping = aes(y = y, x = x)) \n```\n","srcMarkdownNoYaml":"\n\n## Summary\n\nThis firstnchapter lays out the key challenges of statistical inference in general and regression modeling in particular.\n\n::: column-margin\nInference defined as using mathematical models to make general claims from particular data\n:::\n\nThere are three challenges to statistics, which all can be framed as problems of prediction:\\\n- Generalizing from sample to population;\\\n- Generalizing from treatment to control group;\\\n- Generalizing from observed measurements to the underlying construct of interest.\n\nThe key skills you learn in this book are: \\\n- Understanding regression models;\\\n- Constructing regression models;\\\n- Fitting regression models to data;\\\n- Displaying and interpreting the results of regression models;\n\nRegression is a method that allows researchers to summarize how predictions or average values of an *outcome* vary across individuals defined by a set of *predictors*. It is used for example to predict, to explore associations, to extrapolate and for causal inference. Exmaples are given.\n\nThere are four steps in statistical analysis: \\\n- Model building (starting);\\\n- Model fitting;\\\n- Understanding model fits;\\\n- Criticism.\n\nFitting models and making predictions can be down different frameworks. Three concerns are important everytime: \n- Information used;\\\n- Assumptions used;\\\n- Estimating and interpreting (classical or Bayesian framework).\n\nGelman et all. recommend to use the Bayesian framework. If information available you can use it, if not you can use weakly informative default priors. On this way you stable estimates and with the simulations you can express uncertainty.\n\nThe overall Bayesian regression in R is:\n\n:::{.panel-tabset}\n\n## rstanarm\n\n\n```         \nfit<-stan_glm(y~x,data=mydata)\n```\n\n::: column-margin\nBayes can take longer time. Here you can use\n\n```         \nfit<-stan_glm(y~x,data=mydata,algorithm=\"optimizing\")\n```\n:::\n\n## brms\n```\nfit<-brm(y~x,data=mydata)\n```\n\n:::\n\n\n\nWhere y is the outcome, x is the predictor and mydata is the data frame. But you can do it also in classical framework:\n\n```         \nfit<-lm(y~x,data=mydata)\n```\n\nUsing Bayesian and simulation approaches can be more important when fitting multilevel or regularized regression models. This will be handled in their next book.\n\n## Presentation\n\nFirst some libraries are loaded.\n\n```{r warning=FALSE, message=FALSE}\nlibrary(rosdata) # for the ROSdata\nlibrary(dplyr)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(rstanarm) # for the stan_glm function\nlibrary(brms) # for the brm function\n```\n\n\n\n## Presentation\nOn 14-11-2023 Alex Trinidad (University of Cologne and Netherlands Institute for the Study of Crime and Law Enforcement) presented the first chapter of the book *Regression and Other Stories* by Andrew Gelman, Jennifer Hill, and Aki Vehtari: **Overview**. The session was held online via Zoom.\n[Here]() you can find Alex' script Trinidad.\n\nFirst he loaded this package.\n\n```{r message=FALSE, warning=FALSE}\n#| label: load-packages\n\nlibrary(tidyverse)\n```\n\n\n\n1. Regression to predict \n\nHow can we predict presidential vote share using economy growth? For this he loaded the ROS-data.\n\n```{r}\n#| label: load-data1\n\nelections_data <- read.csv(url(\"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/ElectionsEconomy/data/hibbs.dat\"), sep = \"\")\n\n```\n\nThis another way to load these data.\n\n```{r}\n#| label: load-data2\n\nremotes::install_github(\"avehtari/ROS-Examples\", subdir = \"rpackage\")\nelections_data <- rosdata::hibbs\n```\n\n\nLet us first explore economy growth.\n\n```{r}\n#| label: explore-data\n\nglimpse(elections_data)\n```\nTry the view-function yourself.\n\n```{r}\n# View(elections_data)\n```\n\nUse visualization to understand the data.\n\n```{r}\n#| label: plot-data1\n#| fig.cap: \"Predicting elections from the economy 1952-2016\"\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = year, y = growth))\n\n```\n\nAdd a line to the plot.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-data2\n#| fig.cap: \"Predicting elections from the economy 1952-2016 with line\"\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = year, y = growth)) +\n  geom_smooth(aes(x = year, y = growth), se = FALSE)\n```\n\nAdd the CI around the line.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-data3\n#| fig.cap: \"Predicting elections from the economy 1952-2016 with line and confidence interval\"\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = year, y = growth)) +\n  geom_smooth(aes(x = year, y = growth), se = TRUE)\n```\n\nFit ols-regression to obtain the predicted values.\n\n```{r}\n#| label: fit-ols\n\nmod1 <- lm(vote ~ growth, data = elections_data)\n```\n\nSummarize the regression results.\n\n```{r}\n#| label: summary-ols\n\nsummary(mod1)\n```\n\nPlot the predicted values.\n\n```{r}\n#| label: plot-predicted\n#| column: margin\n#| fig.cap: \"Predicting elections from the economy 1952-2016 with line\"\n\nplot(elections_data$growth, elections_data$vote, xlab = \"Economic Growth\", ylab = \"Vote Share\")\nabline(coef(mod1), col = \"red\")\n```\nPredicted values with ggplot.\n\n```{r}\n#| label: plot-predicted2\n#| column: margin\n  \nggplot(data = elections_data) +\n  geom_point(aes(x = growth, y = vote)) +\n  geom_abline(intercept = mod1[[1]][[1]], slope = mod1[[1]][[2]], color = \"red\", size = 1) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  scale_y_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  geom_hline(yintercept = 50) +\n  labs(title = \"Data and linear fit\",\n       x = \"Average recent growth in personal income\",\n       y = \"Incumbent party's vote share\")\n```\n\nPredicted values with ggplot and geom_smooth.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-predicted3\n#| column: margin\n\nggplot(data = elections_data) +\n  geom_point(aes(x = growth, y = vote)) +\n  geom_smooth(method = \"lm\", aes(x = growth, y = vote), color = \"blue\", size = 1) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  scale_y_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  geom_hline(yintercept = 50) +\n  labs(title = \"Data and linear fit\",\n       x = \"Average recent growth in personal income\",\n       y = \"Incumbent party's vote share\")\n```\n\n2. Sketching regression \n\nOriginal $y = 46.3 + 3.0 x$. Explore the descriptive stats to get some parameters based on the observed data.\n\n```{r}\n#| label: descriptive-stats\n\nelections_data |> \n  summarise(min_growth = min(growth),\n            max_growth = max(growth),\n            mean_growth = mean(growth),\n            sd_growth = sd(growth),\n            min_vote = min(vote),\n            max_vote = max(vote),\n            mean_vote = mean(vote),\n            sd_vote = sd(vote))\n```\n\nSimulating the data (technique often used in this book).\n\n```{r}\n#| label: simulate-data\nset.seed(123)\nN <- 16\nsimu_growth <- runif(N, -0.39, 4)\nsimu_vote <- rnorm(N, 46.2476  + 3.0605*simu_growth, 3.763)\nsimu_elections <- data.frame(N,simu_growth, simu_vote)\n```\n\nModel the simulated data.\n\n```{r}\n#| label: model-simulated\nsimu_mod <- lm(simu_vote ~ simu_growth, data = simu_elections)\n```\n\nSummarize the model.\n\n```{r}\n#| label: summary-simulated\nsummary(simu_mod)\n```\n\nPlot the simulated data using base graphics.\n\n```{r}\n#| label: plot-simulated\n#| column: margin\n#| fig.cap: \"Simulated Data and linear fit\"\n\n# Base graphic\nplot(simu_elections$simu_growth, simu_elections$simu_vote, xlab = \"Simulated Economic Growth\", ylab = \"Simulated Vote Share\")\nabline(coef(simu_mod), col = \"blue\")\n```\n\nPlot the samen using ggplot version.\n\n```{r message=FALSE, warning=FALSE}\n#| label: plot-simulated2\n#| column: margin\n \nggplot(data = simu_elections) +\n  geom_point(aes(x = simu_growth, y = simu_vote)) +\n  geom_smooth(method = \"lm\", aes(x = simu_growth, y = simu_vote), color = \"blue\", size = 1) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  scale_y_continuous(labels = scales::label_percent(accuracy = 1, scale = 1)) + \n  geom_hline(yintercept = 50) +\n  labs(title = \"Simulated Data and linear fit\",\n       x = \"Simulated Average recent growth in personal income\",\n       y = \"Simulated Incumbent party's vote share\")\n```\n\nExercise 1.2(a) from ROS for sketching a regression model and data. \n\na) $y = 30 + 10x$  (residual $sd 3.9$) & values of X ranging from $0-4$ \n\nDefine the data.\n\n```{r}\n#| label: exercise-1.2\n\nset.seed(123)\nN <- 50\nx <- runif(N, 0, 4)\ny <- rnorm(N, 30 + 10*x, 3.9)\ndata <- data.frame(N, x, y)\n```\n\nModel the data.\n\n```{r}\n#| label: exercise-1.2-model\nlm_a <- lm(y ~ x, data)\n```\n\nPlot the data.\n\n```{r}\n#| label: exercise-1.2-plot\n#| column: margin\n#| fig.cap: \"Exercise 1.2 from ROS\"\n\nplot(data$x, data$y, xlab = \"X Value\", ylab = \"Y value\")\nabline(coef(lm_a), col = \"red\", size = 1)\n```\n\nb) $y = 30 + 10x$  (residual $sd 10$) & values of X ranging from $0-4$. \n\nDefine the data.\n\n```{r}\n#| label: exercise-1.2b\n\nset.seed(123)\nN <- 50\nx <- runif(N, 0, 4)\ny <- rnorm(N, 30 + 10*x, 10)\ndata <- data.frame(N, x, y)\n```\n\nModel it.\n\n```{r}\n#| label: exercise-1.2b-model\n\nlm_b <- lm(y ~ x, data)\n```\n\nPlot it.\n\n```{r}\n#| label: exercise-1.2b-plot\n#| column: margin\n#| fig.cap: \"Continuous predictor\"\n\nplot(data$x, data$y, xlab = \"X Value\", ylab = \"Y value\")\nabline(coef(lm_b), col = \"blue\")\n```\n\nNow simulate a binary predictor [example from the Aki Vehtari GH](https://avehtari.github.io/ROS-Examples/SimpleCausal/causal.html)\n\nSee Figure 1.5 (page 10).\n\n```{r}\n#| label: binary-predictor\n\nset.seed(1411)\nN <- 50\nx <- runif(N, 0, 4)\ny <- rnorm(N, 30 + 10*x, 10)\nx_binary <- ifelse(x < 3, 0, 1)\ndata_simu <- data.frame(N, x, y, x_binary)\n```\n\nModel it.\n\n```{r}\n#| label: binary-predictor-model\n\nlm_binary <- lm(y ~ x_binary, data = data_simu)\n```\n\nSummarize the model.\n\n```{r}\n#| label: binary-predictor-summary\nsummary(lm_binary)\n```\n\nPlot the relationship.\n\n```{r}\n#| label: binary-predictor-plot\n#| column: margin\n#| fig.cap: \"Binary predictor\"\n\nggplot(data = data_simu) +\n  geom_point(aes(x = x_binary, y = y)) +\n  geom_abline(intercept = lm_binary[[1]][[1]], slope = lm_binary[[1]][[2]],\n              color = \"blue\", size = 1) +\n  labs(y = \"Crime reduction\", \n       x =  NULL) +\n  scale_x_continuous(breaks = c(0,1),\n                     labels = c(\"Control\", \"Treatment\")) +\n  annotate(geom = \"text\", x = 0.50, y = 40,\n           label = paste(\"Estimated treatment effect is\\nslope of fitted line: \",\n                         round(lm_binary[[1]][[2]], digits = 2)))\n```\n\nNon-linear relationship \n\n```{r}\n#| label: non-linear\n\nset.seed(1411)\nx <- runif(N, 1, 7)\ny <- rnorm(N, 7 + 30*exp(-x), 2)\ndata_simu$y <- y\n```\n\nFit the model. \n\n```{r}\n#| label: non-linear-model\n\nlm_nonlinear <- lm(y ~ x, data = data_simu)\n```\n\nSummarize the model.\n\n```{r}\n#| label: non-linear-summary\n\nsummary(lm_nonlinear)\n```           \n\nPlot the model outcome.\n\n```{r message=FALSE, warning=FALSE}\n#| label: non-linear-plot\n#| column: margin\n#| fig.cap: \"Non-linear relationship\"\n\nggplot(data = data_simu) +\n  geom_point(aes(x = x, y = y)) +\n  geom_smooth(method = \"loess\", aes(x = x, y = y), color = \"blue\", size = 1, se = FALSE) +\n  labs(y = \"Theft counts per hour\", \n       x =  \"Hours of foot patrol\")  \n```\n\n## More examples\nFirst look at dataset to predict US-elections (1952-2021) from the economy and explore data.\n\n```{r}\ndata(\"hibbs\")\nglimpse(hibbs)\n```\n\nReplicate the plot of Figure 1.1.\n\n```{r}\n#| label: fig:hibbs\n#| fig-cap: \"Predicting elections from the economy 1952-2016\"\n#| column: margin\n\nggplot(data = hibbs,\n       mapping = aes(x = growth, y = vote)) +\n  # geom_label(mapping = aes(label = year), nudge_x = 0.3, fill = NA, size = 3) +\n  geom_point() \n\n```\n\nNow run the first regression model using `stanarm` or `brms`. This simulation works with four chains and 2000 iterations per chain. \n\n:::{.panel-tabset}\n\n## rstanarm\n\n```{r}\nM1 <- stan_glm(vote ~ growth, data=hibbs)\n```\n\nM1 is set on your computer and you can give a summary of this regression model.\n\n```{r}\nM1\n```\n\nOr print the intercept (46.26) and the slope (3.05) of this model.\n\n```{r}\ncoef(M1)\n```\n\n\n## brms\n\n```{r}\nM2 <- brm(vote ~ growth, data=hibbs)\n```\n\nM2 is set on your computer and you can give a summary of this regression model.\n\n```{r}\nM2 <-\n  brm(data = hibbs,\n      vote ~ growth,\n      cores = 4, chains = 4, iter = 2000,\n      seed = 123)\n\n\n```\n\n```{r}\nM2\n```\n\n\n\n:::\n\nNow add line to plot.\n\n```{r}\n#| label: fig:hibbs2\n#| fig-cap: \"Predicting elections from the economy 1952-2016\"\n#| column: margin\n#| \nggplot(data = hibbs,\n       mapping = aes(x = growth, y = vote)) +\n  geom_point() +\n  geom_abline(slope     = coef(M1)[[\"growth\"]],\n              intercept = coef(M1)[[\"(Intercept)\"]]) \n```\n\n\nWe also looked at the peacekeeping data (1.3). First open the data.\n\n\n```{r warning=FALSE, message=FALSE}\npeace_df <- read_csv(\"~/Desktop/WERK/Gelman/reading_club_GIT/Reading_club_Git/ROS-Examples-master/Peacekeeping/data/minidata.csv\")\n```\n\nExplore this dataset now.\n\n```{r}\nglimpse(peace_df)\n```\n\nCreate date measure. It's actually the same as delay.\n\n```{r}\npeace_df <- peace_df |>\n  mutate(time_diff = (faildate-cfdate)/365)\n```\n\nLet us plot it ...\n\n```{r}\n#| label: fig:peace\n#| fig-cap: \"Outcomes after civil war in countries with and without UN-peacekeepers\"\n#| column: margin\n\n# Harrie: not working\n# peace_df |>\n#  ggplot(data = .) +\n#  geom_histogram(mapping = aes(x = delay), bins = 10) +\n#  facet_wrap(~`peacekeepers?`) \n```\n\n... or put it in a scatterplot.\n\n```{r}\n#| label: fig:peace2\n#| fig-cap: \"Outcomes after civil war in countries with and without UN-peacekeepers\"\n#| column: margin\n\nggplot(data = peace_df) +\n  geom_point(mapping = aes(y = delay,\n                           colour = as.factor(`censored?`),\n                           x = badness,\n                           )) +\n  facet_wrap(~`peacekeepers?`) \n```\n\nMeans.\n\n```{r warning=FALSE, message=FALSE}\npeace_df |> \n  group_by(`peacekeepers?`, `censored?`) |> \n  summarise(mean_badness = mean(badness, na.rm = TRUE))\n```\n\nSimple causal graph for reproducibility of simulated data.\n\n```{r}\nSEED <- 1151\nset.seed(SEED)\nN <- 50\nx <- runif(N, 1, 5)\ny <- rnorm(N, 10 + 3*x, 3)\nx_binary <- ifelse(x<3, 0, 1)\ncausal_df <- data.frame(N, x, y, x_binary)\n```\n\nPlot this.\n\n```{r}\n#| label: fig:causal\n#| fig-cap: \"Causal graph of simulated data\"\n#| column: margin\n#| \nggplot(data = causal_df) +\n  geom_point(mapping = aes(y = y, x = x)) \n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","reference-location":"margin","output-file":"01-chapter.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["references.bib"],"theme":"cosmo","title":"Overview","author":"Alex Trinidad (Chair)","citation-location":"margin","grid":{"margin-width":"350px"}},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","reference-location":"margin","output-file":"01-chapter.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"documentclass":"scrreprt","title":"Overview","author":"Alex Trinidad (Chair)","citation-location":"margin"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}