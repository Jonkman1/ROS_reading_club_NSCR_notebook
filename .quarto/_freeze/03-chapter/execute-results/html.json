{
  "hash": "5dba2fe88a2d6d4944087b34065083d5",
  "result": {
    "markdown": "---\ntitle: \"Some basic methods in mathematics and probability\"\nauthor: \" X Y (Chair)\"\nformat:\n  html: \n    grid: \n      margin-width: 350px\n  pdf: default\nreference-location: margin\ncitation-location: margin\n---\n\n\n## Summary\n\nSimple methods from introductory mathematics and probability have three important roles in regression modelling. \\\n- Linear algebra and simple probability distributions are the building blocks for elaborate models. \\\n- It is useful to understand the basic ideas of inference separately from the details of particular class of model. \\\n- It is often useful in practice to construct quick estimates and comparisons for small parts of a problem - before fitting an elaborate model, or in understanding the output from such a model.\\\nThis chapter provides a quick review of some of these basic ideas.\n\nFirst some ideas from algebra are presented:\n- *Weighted averages* are used to adept to a target population (for eg. the average age of all North American as a weighted average). \\\n- *Vectors* are used to represent a collection of numbers and *matrices* are used to represent a collection of vectors. \\\n- To use linear regression effectively, you need to understand the algebra and geometry of straight *lines*, with the intercept and the slope. \n- To use *logarithmic* and *log-log relationships* for exponential and power-law growth and decline.\n\nHere an example of a regression line.\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n#\nlibrary(tidyverse)\nlibrary(patchwork)\n# Thanks Solomon Kurz \n# set the global plotting theme\ntheme_set(theme_linedraw() +\n            theme(panel.grid = element_blank()))\n\na <- 0\nb <- 1\n\n# left\np1 <-\n  tibble(x = 0:2) %>% \n  mutate(y = a + b * x) %>%\n  \n  ggplot(aes(x = x, y = y)) +\n  geom_line() +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), breaks = 0:2) +\n  scale_y_continuous(breaks = 0:2, labels = c(\"a\", \"a+b\", \"a+2b\")) +\n  labs(subtitle = expression(y==a+bx~(with~b>0)))\n\nb <- -1\n\n# right\np2 <-\n  tibble(x = 0:2) %>% \n  mutate(y = a + b * x) %>%\n  \n  ggplot(aes(x = x, y = y)) +\n  geom_line() +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), breaks = 0:2) +\n  scale_y_continuous(breaks = 0:-2, labels = c(\"a\", \"a+b\", \"a+2b\")) +\n  labs(subtitle = expression(y==a+bx~(with~b<0)))\n\n# combine with patchwork\nlibrary(patchwork)\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](03-chapter_files/figure-html/fig-regression-lines-1.png){width=672}\n:::\n:::\n\n\n\n\n*Probabilistic distributions* are used in regression modeling to help to characterize the variation that remains *after* predicting the average. These distributions allow us to get a handle on how uncertain our predictions are and, additionally, our uncertainty in the estimated parameters of the model. *Mean* (expected value), *variance* (mean of squared difference from the mean), and *standard deviation* (square root of variance) are the basic concepts of probability distributions.\n\nNormal distribution, binomial distribution, and Poisson distribution and Unclassified probability distributions are types of probability distributions presented here. They will be worked out in detail in the following chapters.\n\nIn regression we typically model as much of the data variation as possible with a *deterministic* model, with a probability distribution included to capture the *error*, or unexplained variation. Distributions can be used to compare using such as the mean, but also to look at shifts in quantiles for example. Probability distributions can also be used for predicting new outcomes.\n\n## Presentation\n",
    "supporting": [
      "03-chapter_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}